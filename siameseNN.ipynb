{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "siameseNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi1NEf6FG3xV",
        "outputId": "026c9955-f07d-456f-dc91-fb6c53f11400"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "!pip install ray\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "!pip install tensorboardX\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/divergence_hashing_2')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.8.0-cp37-cp37m-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.41.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 487 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Installing collected packages: redis, ray\n",
            "Successfully installed ray-1.8.0 redis-3.5.3\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWiAgBJSuWzmZtexMS-ERkOpitCfevApld-CpiQSih8yzXa-PO4K048\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIwjO93f8ANS"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC1BfeA6HbA4"
      },
      "source": [
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, sequence_pairs):\n",
        "        self.len = len(sequence_pairs[0])\n",
        "        self.original_sequences = sequence_pairs[0]\n",
        "        self.mutated_sequences = sequence_pairs[1]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        original_sequence = self.original_sequences[index]\n",
        "        mutated_sequence = self.mutated_sequences[index]\n",
        "\n",
        "        return {\n",
        "            'original_sequence': original_sequence,\n",
        "            'mutated_sequence': mutated_sequence\n",
        "        }\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8CSKzZnPTml"
      },
      "source": [
        "def makelen128(sequence):\n",
        "\n",
        "    old_len = len(sequence)\n",
        "    new_seq = []\n",
        "\n",
        "    for i in range(0,128):\n",
        "        index = i%old_len\n",
        "        new_seq.append(sequence[index])\n",
        "    \n",
        "    new_seq = ''.join(map(str, new_seq))\n",
        "\n",
        "    return new_seq\n",
        "\n",
        "def has_homopolymer(seq):\n",
        "\n",
        "    same_conseq = 0\n",
        "    previous = None\n",
        "    flag = False\n",
        "    start_pos = -1\n",
        "    end_pos = -1\n",
        "    in_run = False\n",
        "    position_list = []\n",
        "    homopolymering = False\n",
        "\n",
        "    for i in range(len(seq)):\n",
        "        current = seq[i]\n",
        "        if current is previous and current is not None:\n",
        "            same_conseq += 1\n",
        "            if same_conseq is 4:\n",
        "                flag = True\n",
        "                homopolymering = True\n",
        "        if current is not previous or i is (len(seq)-1):\n",
        "            same_conseq = 1\n",
        "            if homopolymering is True:\n",
        "                position_list.append([start_pos, i]) # end-exclusive\n",
        "                homopolymering = False\n",
        "            start_pos = i\n",
        "        previous = current\n",
        "\n",
        "    return flag, position_list\n",
        "\n",
        "\n",
        "def produces_homopolymer(seq, position, base):\n",
        "\n",
        "    old_flag, old_position_list = has_homopolymer(seq)\n",
        "    copy_seq = seq[:]\n",
        "    copy_seq[position] = base\n",
        "    flag, position_list = has_homopolymer(copy_seq)\n",
        "    if len(position_list) > len(old_position_list):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def get_CG_count(temp, primer_length):\n",
        "\n",
        "    if primer_length < 14:\n",
        "        CG_count = int((temp-primer_length*2)/2)\n",
        "\n",
        "    elif primer_length == 18 and temp >= 43 and temp <= 72:\n",
        "        if temp >= 43 and temp < 46:\n",
        "            CG_count = 6\n",
        "        elif temp >= 46 and temp < 48:\n",
        "            CG_count = 7\n",
        "        elif temp >= 48 and temp < 51:\n",
        "            CG_count = 8\n",
        "        elif temp >= 51 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 56:\n",
        "            CG_count = 10\n",
        "        elif temp >= 56 and temp < 59:\n",
        "            CG_count = 11\n",
        "        elif temp >= 59 and temp < 62:\n",
        "            CG_count = 12\n",
        "        elif temp >= 62 and temp < 65:\n",
        "            CG_count = 13\n",
        "        elif temp >= 65 and temp < 68:\n",
        "            CG_count = 14\n",
        "        elif temp >= 68 and temp < 71:\n",
        "            CG_count = 15\n",
        "        elif temp >= 71 and temp <= 72:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 19 and temp >= 44 and temp <= 71:\n",
        "        if temp >= 44 and temp < 46:\n",
        "            CG_count = 6\n",
        "        elif temp >= 46 and temp < 49:\n",
        "            CG_count = 7\n",
        "        elif temp >= 49 and temp < 51:\n",
        "            CG_count = 8\n",
        "        elif temp >= 51 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 57:\n",
        "            CG_count = 10\n",
        "        elif temp >= 57 and temp < 59:\n",
        "            CG_count = 11\n",
        "        elif temp >= 59 and temp < 62:\n",
        "            CG_count = 12\n",
        "        elif temp >= 62 and temp < 65:\n",
        "            CG_count = 13\n",
        "        elif temp >= 65 and temp < 68:\n",
        "            CG_count = 14\n",
        "        elif temp >= 68 and temp < 70:\n",
        "            CG_count = 15\n",
        "        elif temp >= 70 and temp <= 71:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 20 and temp >= 45 and temp <= 70:\n",
        "        if temp >= 45 and temp < 47:\n",
        "            CG_count = 6\n",
        "        elif temp >= 47 and temp < 49:\n",
        "            CG_count = 7\n",
        "        elif temp >= 49 and temp < 52:\n",
        "            CG_count = 8\n",
        "        elif temp >= 52 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 57:\n",
        "            CG_count = 10\n",
        "        elif temp >= 57 and temp < 59:\n",
        "            CG_count = 11\n",
        "        elif temp >= 59 and temp < 61:\n",
        "            CG_count = 12\n",
        "        elif temp >= 61 and temp < 64:\n",
        "            CG_count = 13\n",
        "        elif temp >= 64 and temp < 66:\n",
        "            CG_count = 14\n",
        "        elif temp >= 66 and temp < 69:\n",
        "            CG_count = 15\n",
        "        elif temp >= 69 and temp <= 70:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 21 and temp >= 45 and temp <= 70:\n",
        "        if temp >= 45 and temp < 47:\n",
        "            CG_count = 6\n",
        "        elif temp >= 47 and temp < 49:\n",
        "            CG_count = 7\n",
        "        elif temp >= 49 and temp < 52:\n",
        "            CG_count = 8\n",
        "        elif temp >= 52 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 56:\n",
        "            CG_count = 10\n",
        "        elif temp >= 56 and temp < 59:\n",
        "            CG_count = 11\n",
        "        elif temp >= 59 and temp < 61:\n",
        "            CG_count = 12\n",
        "        elif temp >= 61 and temp < 63:\n",
        "            CG_count = 13\n",
        "        elif temp >= 63 and temp < 66:\n",
        "            CG_count = 14\n",
        "        elif temp >= 66 and temp < 69:\n",
        "            CG_count = 15\n",
        "        elif temp >= 69 and temp <= 70:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 22 and temp >= 46 and temp <= 69:\n",
        "        if temp >= 46 and temp < 48:\n",
        "            CG_count = 6\n",
        "        elif temp >= 48 and temp < 50:\n",
        "            CG_count = 7\n",
        "        elif temp >= 50 and temp < 52:\n",
        "            CG_count = 8\n",
        "        elif temp >= 52 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 56:\n",
        "            CG_count = 10\n",
        "        elif temp >= 56 and temp < 58:\n",
        "            CG_count = 11\n",
        "        elif temp >= 58 and temp < 61:\n",
        "            CG_count = 12\n",
        "        elif temp >= 61 and temp < 63:\n",
        "            CG_count = 13\n",
        "        elif temp >= 63 and temp < 65:\n",
        "            CG_count = 14\n",
        "        elif temp >= 65 and temp < 68:\n",
        "            CG_count = 15\n",
        "        elif temp >= 68 and temp <= 69:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 23 and temp >= 46 and temp <= 68:\n",
        "        if temp >= 46 and temp < 48:\n",
        "            CG_count = 6\n",
        "        elif temp >= 48 and temp < 50:\n",
        "            CG_count = 7\n",
        "        elif temp >= 50 and temp < 51:\n",
        "            CG_count = 8\n",
        "        elif temp >= 51 and temp < 53:\n",
        "            CG_count = 9\n",
        "        elif temp >= 53 and temp < 55:\n",
        "            CG_count = 10\n",
        "        elif temp >= 55 and temp < 57:\n",
        "            CG_count = 11\n",
        "        elif temp >= 57 and temp < 61:\n",
        "            CG_count = 12\n",
        "        elif temp >= 61 and temp < 63:\n",
        "            CG_count = 13\n",
        "        elif temp >= 63 and temp < 65:\n",
        "            CG_count = 14\n",
        "        elif temp >= 65 and temp < 67:\n",
        "            CG_count = 15\n",
        "        elif temp >= 67 and temp <= 68:\n",
        "            CG_count = 16\n",
        "\n",
        "    elif primer_length == 24 and temp >= 47 and temp <= 68:\n",
        "        if temp >= 47 and temp < 49:\n",
        "            CG_count = 6\n",
        "        elif temp >= 49 and temp < 51:\n",
        "            CG_count = 7\n",
        "        elif temp >= 51 and temp < 52:\n",
        "            CG_count = 8\n",
        "        elif temp >= 52 and temp < 54:\n",
        "            CG_count = 9\n",
        "        elif temp >= 54 and temp < 56:\n",
        "            CG_count = 10\n",
        "        elif temp >= 56 and temp < 58:\n",
        "            CG_count = 11\n",
        "        elif temp >= 58 and temp < 60:\n",
        "            CG_count = 12\n",
        "        elif temp >= 60 and temp < 62:\n",
        "            CG_count = 13\n",
        "        elif temp >= 62 and temp < 65:\n",
        "            CG_count = 14\n",
        "        elif temp >= 65 and temp < 67:\n",
        "            CG_count = 15\n",
        "        elif temp >= 67 and temp <= 68:\n",
        "            CG_count = 16\n",
        "\n",
        "    else:\n",
        "        CG_count = int(round(0.865*((primer_length*(temp - 64.9))/41 + 16.4)))\n",
        "    \n",
        "    CG_count = max(0, CG_count)\n",
        "    CG_count = min(CG_count, primer_length)\n",
        "    return CG_count\n",
        "\n",
        "\n",
        "def seq_to_temp(seq):\n",
        "\n",
        "    primer_length = len(seq)\n",
        "    CG_count = 0\n",
        "    dict = {\n",
        "        'A': 0,\n",
        "        'T': 0,\n",
        "        'C': 1,\n",
        "        'G': 1\n",
        "    }       \n",
        "\n",
        "    for base in seq:\n",
        "        CG_count += dict[base] \n",
        "\n",
        "    if primer_length < 14:\n",
        "        temp = CG_count*4 + (primer_length-CG_count)*2\n",
        "\n",
        "    elif primer_length == 18 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 43.9\n",
        "        elif CG_count == 7:\n",
        "            temp = 46.3\n",
        "        elif CG_count == 8:\n",
        "            temp = 49.4\n",
        "        elif CG_count == 9:\n",
        "            temp = 51.7\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.4\n",
        "        elif CG_count == 11:\n",
        "            temp = 57.2\n",
        "        elif CG_count == 12:\n",
        "            temp = 60.2\n",
        "        elif CG_count == 13:\n",
        "            temp = 63.2\n",
        "        elif CG_count == 14:\n",
        "            temp = 66.4\n",
        "        elif CG_count == 15:\n",
        "            temp = 69.0\n",
        "        elif CG_count == 16:\n",
        "            temp = 71.7\n",
        "\n",
        "    elif primer_length == 19 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 44.6\n",
        "        elif CG_count == 7:\n",
        "            temp = 47.0\n",
        "        elif CG_count == 8:\n",
        "            temp = 49.5\n",
        "        elif CG_count == 9:\n",
        "            temp = 52.1\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.7\n",
        "        elif CG_count == 11:\n",
        "            temp = 57.3\n",
        "        elif CG_count == 12:\n",
        "            temp = 60.0\n",
        "        elif CG_count == 13:\n",
        "            temp = 62.7\n",
        "        elif CG_count == 14:\n",
        "            temp = 65.7\n",
        "        elif CG_count == 15:\n",
        "            temp = 68.5\n",
        "        elif CG_count == 16:\n",
        "            temp = 70.8\n",
        "\n",
        "    elif primer_length == 20 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 45.2\n",
        "        elif CG_count == 7:\n",
        "            temp = 47.5\n",
        "        elif CG_count == 8:\n",
        "            temp = 50.2\n",
        "        elif CG_count == 9:\n",
        "            temp = 52.4\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.5\n",
        "        elif CG_count == 11:\n",
        "            temp = 57.0\n",
        "        elif CG_count == 12:\n",
        "            temp = 59.7\n",
        "        elif CG_count == 13:\n",
        "            temp = 62.1\n",
        "        elif CG_count == 14:\n",
        "            temp = 64.6\n",
        "        elif CG_count == 15:\n",
        "            temp = 67.4\n",
        "        elif CG_count == 16:\n",
        "            temp = 70.1\n",
        "\n",
        "    elif primer_length == 21 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 45.4\n",
        "        elif CG_count == 7:\n",
        "            temp = 47.8\n",
        "        elif CG_count == 8:\n",
        "            temp = 50.0\n",
        "        elif CG_count == 9:\n",
        "            temp = 52.2\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.5\n",
        "        elif CG_count == 11:\n",
        "            temp = 57.0\n",
        "        elif CG_count == 12:\n",
        "            temp = 59.3\n",
        "        elif CG_count == 13:\n",
        "            temp = 61.8\n",
        "        elif CG_count == 14:\n",
        "            temp = 64.3\n",
        "        elif CG_count == 15:\n",
        "            temp = 66.9\n",
        "        elif CG_count == 16:\n",
        "            temp = 69.6\n",
        "\n",
        "    elif primer_length == 22 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 46.1\n",
        "        elif CG_count == 7:\n",
        "            temp = 48.1\n",
        "        elif CG_count == 8:\n",
        "            temp = 50.3\n",
        "        elif CG_count == 9:\n",
        "            temp = 52.5\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.7\n",
        "        elif CG_count == 11:\n",
        "            temp = 56.9\n",
        "        elif CG_count == 12:\n",
        "            temp = 59.1\n",
        "        elif CG_count == 13:\n",
        "            temp = 61.3\n",
        "        elif CG_count == 14:\n",
        "            temp = 63.6\n",
        "        elif CG_count == 15:\n",
        "            temp = 66.0\n",
        "        elif CG_count == 16:\n",
        "            temp = 68.3\n",
        "\n",
        "    elif primer_length == 23 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 46.6\n",
        "        elif CG_count == 7:\n",
        "            temp = 48.7\n",
        "        elif CG_count == 8:\n",
        "            temp = 50.8\n",
        "        elif CG_count == 9:\n",
        "            temp = 52.7\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.8\n",
        "        elif CG_count == 11:\n",
        "            temp = 56.9\n",
        "        elif CG_count == 12:\n",
        "            temp = 59.0\n",
        "        elif CG_count == 13:\n",
        "            temp = 61.2\n",
        "        elif CG_count == 14:\n",
        "            temp = 63.4\n",
        "        elif CG_count == 15:\n",
        "            temp = 65.5\n",
        "        elif CG_count == 16:\n",
        "            temp = 67.8\n",
        "\n",
        "    elif primer_length == 24 and CG_count >= 6 and CG_count <= 16:\n",
        "        if CG_count == 6:\n",
        "            temp = 47.2\n",
        "        elif CG_count == 7:\n",
        "            temp = 49.1\n",
        "        elif CG_count == 8:\n",
        "            temp = 51.0\n",
        "        elif CG_count == 9:\n",
        "            temp = 53.0\n",
        "        elif CG_count == 10:\n",
        "            temp = 54.9\n",
        "        elif CG_count == 11:\n",
        "            temp = 56.9\n",
        "        elif CG_count == 12:\n",
        "            temp = 58.9\n",
        "        elif CG_count == 13:\n",
        "            temp = 60.9\n",
        "        elif CG_count == 14:\n",
        "            temp = 62.9\n",
        "        elif CG_count == 15:\n",
        "            temp = 65.1\n",
        "        elif CG_count == 16:\n",
        "            temp = 67.2\n",
        "    else:\n",
        "        temp = 64.9 + 41*(CG_count-16.4)/primer_length\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def logits_to_primer(logits, temp, primer_length):\n",
        "\n",
        "    CG_count = get_CG_count(temp, primer_length)\n",
        "\n",
        "    logits = nn.functional.softmax(logits, dim = 1)\n",
        "    logits = torch.transpose(logits, 2, 1) #returns 6,128,4\n",
        "    logits = logits[:, :primer_length, :]\n",
        "    pred = torch.argmax(logits, 2)\n",
        "    pred = pred.tolist() #returns list of list (6, 128)\n",
        "    size = list(logits.size())\n",
        "    sequence_list = []\n",
        "    int2base = {0: \"A\", 1: \"T\", 2: \"C\", 3: \"G\"}\n",
        "\n",
        "    for seq in range(size[0]):\n",
        "        CG_some_data = []\n",
        "        AT_some_data = []\n",
        "        sequence = [None]*size[1]\n",
        "        base_sequence = [None]*size[1]\n",
        "        for position in range(size[1]):\n",
        "            data0 = [2, logits[seq][position][2], position]\n",
        "            data1 = [3, logits[seq][position][3], position]\n",
        "            CG_some_data.append(data0)\n",
        "            CG_some_data.append(data1)\n",
        "\n",
        "            data0 = [0, logits[seq][position][0], position]\n",
        "            data1 = [1, logits[seq][position][1], position]\n",
        "            AT_some_data.append(data0)\n",
        "            AT_some_data.append(data1)\n",
        "        CG_sorted_some_data = sorted(range(len(CG_some_data)), key = lambda k: CG_some_data[k][1], reverse=True)\n",
        "        AT_sorted_some_data = sorted(range(len(CG_some_data)), key = lambda k: AT_some_data[k][1], reverse=True)\n",
        "\n",
        "        # try to place CGs without causing homopolymers\n",
        "        placed_CG = 0\n",
        "        for i in range(len(CG_sorted_some_data)):\n",
        "            if placed_CG < CG_count:\n",
        "                index = CG_sorted_some_data[i]\n",
        "                base = CG_some_data[index][0]\n",
        "                position = CG_some_data[index][2]\n",
        "                if sequence[position] is None and not produces_homopolymer(sequence, position, base):\n",
        "                    sequence[position] = base\n",
        "                    placed_CG+=1\n",
        "\n",
        "        # check for 5' and 3' GC clamps (since extension happens from 3' of this primer and the complementary primer)\n",
        "        five_prime_GC_clamp = 0\n",
        "        three_prime_GC_clamp = 0\n",
        "        mid_GC_count = 0\n",
        "\n",
        "        for i in range(5):\n",
        "            if sequence[i] is not None:\n",
        "                five_prime_GC_clamp+= 1\n",
        "        \n",
        "        for i in range(len(sequence)-1, len(sequence)-6, -1):\n",
        "            if sequence[i] is not None:\n",
        "                three_prime_GC_clamp+= 1\n",
        "\n",
        "        for i in range(5, len(sequence)-1):\n",
        "            if sequence[i] is not None:\n",
        "                mid_GC_count+=1\n",
        "\n",
        "        CG_to_add = 0\n",
        "        # remove GCs in excess of 3 in five_prime_GC_clamp\n",
        "        for i in range(len(CG_sorted_some_data)-1, -1, -1):\n",
        "            if five_prime_GC_clamp > 3:\n",
        "                index = CG_sorted_some_data[i]\n",
        "                base = CG_some_data[index][0]\n",
        "                position = CG_some_data[index][2]\n",
        "                if position < 5 and sequence[position] is not None:\n",
        "                    sequence[position] = None\n",
        "                    CG_to_add+=1\n",
        "                    five_prime_GC_clamp-=1\n",
        "\n",
        "        # remove GCs in excess of 3 in three_prime_GC_clamp\n",
        "        for i in range(len(CG_sorted_some_data)-1, -1, -1):\n",
        "            if three_prime_GC_clamp > 3:\n",
        "                index = CG_sorted_some_data[i]\n",
        "                base = CG_some_data[index][0]\n",
        "                position = CG_some_data[index][2]\n",
        "                if position > primer_length-6 and sequence[position] is not None:\n",
        "                    sequence[position] = None\n",
        "                    CG_to_add+=1\n",
        "                    three_prime_GC_clamp-=1\n",
        "\n",
        "        # add back GCs elsewhere\n",
        "        pointer = 0 # those before were already placed or not placed as they cause homopolymers\n",
        "        while CG_to_add > 0 and pointer is not len(CG_sorted_some_data):\n",
        "            index = CG_sorted_some_data[pointer]\n",
        "            base = CG_some_data[index][0]\n",
        "            position = CG_some_data[index][2]\n",
        "            if sequence[position] is None and not produces_homopolymer(sequence, position, base):\n",
        "                if position > 4 and position < primer_length-5:\n",
        "                    sequence[position] = base\n",
        "                    CG_to_add-=1                \n",
        "                    mid_GC_count+=1\n",
        "                elif position < 5 and five_prime_GC_clamp < 3:\n",
        "                    sequence[position] = base\n",
        "                    CG_to_add-=1\n",
        "                    five_prime_GC_clamp+=1\n",
        "                elif position > primer_length-6 and three_prime_GC_clamp < 3:\n",
        "                    sequence[position] = base\n",
        "                    CG_to_add-=1\n",
        "                    three_prime_GC_clamp+=1\n",
        "            pointer+=1\n",
        "\n",
        "        # if we still were not able to put back the GCs elsewhere, then put it back anyway\n",
        "        #(even if this results in more than 3 CGs in the ends)\n",
        "        #(e.g. if a ridiculously high temp that causes the whole seq to be CGs was set)\n",
        "        pointer = 0\n",
        "        while CG_to_add > 0 and pointer is not len(CG_sorted_some_data):\n",
        "            index = CG_sorted_some_data[pointer]\n",
        "            base = CG_some_data[index][0]\n",
        "            position = CG_some_data[index][2]\n",
        "            if sequence[position] is None and not produces_homopolymer(sequence, position, base):\n",
        "                sequence[position] = base\n",
        "                CG_to_add-=1\n",
        "                if position > 4 and position < primer_length-5:                \n",
        "                    mid_GC_count+=1\n",
        "                elif position < 5 and five_prime_GC_clamp < 3:\n",
        "                    five_prime_GC_clamp+=1\n",
        "                elif position > primer_length-6 and three_prime_GC_clamp < 3:\n",
        "                    three_prime_GC_clamp+=1\n",
        "            pointer+=1\n",
        "\n",
        "        # if 5' GC clamp not present and there is at least one GC in the flanked region or more than one in 3' region\n",
        "        # (to remove after for temp considerations), add the 5' GC clamp\n",
        "        if five_prime_GC_clamp is 0 and (mid_GC_count is not 0 or three_prime_GC_clamp > 1):\n",
        "            for i in range(CG_count, len(CG_sorted_some_data)):\n",
        "                index = CG_sorted_some_data[i]\n",
        "                position = CG_some_data[index][2]\n",
        "                base = CG_some_data[index][0]\n",
        "                if position < 5 and not produces_homopolymer(sequence, position, base):\n",
        "                    sequence[position] = base\n",
        "                    five_prime_GC_clamp+=1\n",
        "                    break\n",
        "\n",
        "            if three_prime_GC_clamp > 1:\n",
        "                # remove a GC from the flanked region or the 3' region by going from the least probable CG\n",
        "                for i in range(len(CG_sorted_some_data)-1, -1, -1):\n",
        "                    index = CG_sorted_some_data[i]\n",
        "                    position = CG_some_data[index][2]\n",
        "                    base = CG_some_data[index][0]\n",
        "                    if position > 4 and position < primer_length-5 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        mid_GC_count-=1\n",
        "                        break\n",
        "                    elif position > primer_length-6 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        three_prime_GC_clamp-=1\n",
        "                        break                        \n",
        "\n",
        "            else:\n",
        "                # remove a GC from the flanked region\n",
        "                for i in range(len(CG_sorted_some_data)-1, -1, -1):\n",
        "                    index = CG_sorted_some_data[pointer]\n",
        "                    position = CG_some_data[index][2]\n",
        "                    base = CG_some_data[index][0]\n",
        "                    if position > 4 and position < primer_length-5 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        mid_GC_count-=1\n",
        "                        break                      \n",
        "\n",
        "        # if 3' GC clamp not present and there are at least two GCs elsewhere (one in 5' region one in flanking) add the 3' GC clamp\n",
        "        if three_prime_GC_clamp is 0 and (mid_GC_count is not 0 or five_prime_GC_clamp > 1):\n",
        "            for i in range(CG_count, primer_length):\n",
        "                index = CG_sorted_some_data[i]\n",
        "                position = CG_some_data[index][2]\n",
        "                base = CG_some_data[index][0]\n",
        "                if position > primer_length-6 and not produces_homopolymer(sequence, position, base):\n",
        "                    sequence[position] = base\n",
        "                    three_prime_GC_clamp+=1\n",
        "                    break\n",
        "\n",
        "            if five_prime_GC_clamp > 1:\n",
        "                # remove a GC from the flanked region or the 3' region by going from the least probable CG\n",
        "                for i in range(len(CG_sorted_some_data)-1, - 1, -1):\n",
        "                    index = CG_sorted_some_data[i]\n",
        "                    position = CG_some_data[index][2]\n",
        "                    base = CG_some_data[index][0]\n",
        "                    if position > 4 and position < primer_length-5 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        mid_GC_count-=1\n",
        "                        break\n",
        "                    elif position < 5 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        five_prime_GC_clamp-=1\n",
        "                        break                        \n",
        "\n",
        "            else:\n",
        "                for i in range(len(CG_sorted_some_data)-1, -1, -1):\n",
        "                    index = CG_sorted_some_data[i]\n",
        "                    position = CG_some_data[index][2]\n",
        "                    base = CG_some_data[index][0]\n",
        "                    # if it is in the flanked region and has yet to be removed\n",
        "                    if position > 4 and position < primer_length-5 and sequence[position] is not None:\n",
        "                        sequence[position] = None\n",
        "                        mid_GC_count-=1\n",
        "                        break        \n",
        "\n",
        "        for i in range(len(AT_sorted_some_data)):\n",
        "            index = AT_sorted_some_data[i]\n",
        "            position = AT_some_data[index][2]\n",
        "            base = AT_some_data[index][0]\n",
        "            if sequence[position] is None and not produces_homopolymer(sequence, position, base):\n",
        "                sequence[position] = base\n",
        "\n",
        "        for i in range(len(sequence)):\n",
        "            base_sequence[i] = int2base[int(sequence[i])]\n",
        "        base_sequence = ''.join(map(str, base_sequence))\n",
        "        sequence_list.append(base_sequence)\n",
        "    return sequence_list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRhd0-mwO0hX"
      },
      "source": [
        "class SiameseModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, single_model):\n",
        "\n",
        "        super().__init__()\n",
        "        self.single_model = single_model\n",
        "\n",
        "    def forward(self, input_0, input_1):\n",
        "\n",
        "        logits_0, original_0, sequence_list_0 = self.single_model(input_0)\n",
        "\n",
        "        logits_1, original_1, sequence_list_1 = self.single_model(input_1)\n",
        "\n",
        "        loss_fct = nn.KLDivLoss()\n",
        "\n",
        "        b_original_mismatches = []\n",
        "        b_mismatches = []\n",
        "        b_loss = 0\n",
        "        total_mismatches = 0\n",
        "            \n",
        "        size = len(input_0)\n",
        "        for x in range(size):\n",
        "            mismatches = sum(1 for a, b in zip(sequence_list_0[x], sequence_list_1[x]) if a != b)\n",
        "            total_mismatches += mismatches\n",
        "            b_mismatches.append(mismatches)\n",
        "\n",
        "            original_mismatches = sum(1 for a, b in zip(original_0[x], original_1[x]) if a != b)\n",
        "            b_original_mismatches.append(original_mismatches)\n",
        "\n",
        "            scaled_logits_0 = torch.mul(logits_0[x],10)\n",
        "            scaled_logits_1 = torch.mul(logits_1[x],10)\n",
        "            loss = -loss_fct(torch.nn.functional.log_softmax(logits_0,dim=0), torch.nn.functional.softmax(logits_1,dim=0))\n",
        "            b_loss += loss\n",
        "\n",
        "        average_mismatches = total_mismatches/size\n",
        "\n",
        "        if b_loss < -100:\n",
        "            print(logits_0)\n",
        "            raise ValueError()\n",
        "        return b_loss, average_mismatches, (original_0, original_1), b_original_mismatches, (sequence_list_0, sequence_list_1), b_mismatches, (logits_0, logits_1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqZFYfcJNCg"
      },
      "source": [
        "def seq_to_tensor(input):\n",
        "    array = []\n",
        "    base_to_int = {\n",
        "        'A': 0,\n",
        "        'T': 1,\n",
        "        'C': 2,\n",
        "        'G': 3\n",
        "    }\n",
        "    for i in input:\n",
        "        array.append(base_to_int[i])\n",
        "    rows = np.max(array) + 1\n",
        "    one_hot = np.eye(rows)[array]\n",
        "    one_hot_transpose = np.transpose(one_hot)\n",
        "    return one_hot_transpose\n",
        "\n",
        "def multiple_seq_to_tensor(input_list):\n",
        "    output_list = []\n",
        "    for i in range(len(input_list)):\n",
        "        array = seq_to_tensor(input_list[i])\n",
        "        output_list.append(array.tolist())\n",
        "    tensor = torch.tensor(output_list)\n",
        "    return tensor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gV3vSd6Rnz_"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, output_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.fc3 = nn.Linear(hidden2_size, hidden3_size)\n",
        "        self.fc4 = nn.Linear(hidden3_size, output_size)\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
        "        nn.init.kaiming_uniform_(self.fc2.weight)\n",
        "        nn.init.kaiming_uniform_(self.fc3.weight)\n",
        "        nn.init.kaiming_uniform_(self.fc4.weight)\n",
        "    \n",
        "    def logits_to_seq(self, logits):\n",
        "\n",
        "        logits = torch.transpose(logits, 2, 1) #returns 6,128,4\n",
        "\n",
        "        # return list of list\n",
        "        pred = torch.argmax(logits, 2)\n",
        "        pred = pred.tolist()\n",
        "\n",
        "        size = list(logits.size())\n",
        "        int_to_base = {\n",
        "          0: \"A\",\n",
        "          1: \"T\",\n",
        "          2: \"C\",\n",
        "          3: \"G\"\n",
        "        }\n",
        "        sequence_list = [None]*len(pred)\n",
        "\n",
        "        for seq in range(size[0]):\n",
        "          for base in range(size[1]):\n",
        "              pred[seq][base] = int_to_base[pred[seq][base]]\n",
        "          sequence = ''.join(map(str, pred[seq]))\n",
        "          sequence_list[seq] = sequence\n",
        "        return sequence_list\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_in = self.logits_to_seq(x)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        seq_out = self.logits_to_seq(x)\n",
        "        return x, seq_in, seq_out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzL2ZPhph5O"
      },
      "source": [
        "config=\"tuned\"\n",
        "n_gpu = 1\n",
        "root_dir = ''\n",
        "\n",
        "class Regressor():\n",
        "\n",
        "    def __init__(self, nb_epoch=1000, config=None):\n",
        "\n",
        "        super(Regressor, self).__init__()\n",
        "\n",
        "        if config is not None:\n",
        "            self.nb_epoch = config[\"num_epochs\"]\n",
        "            self.batch_size = config[\"batch_size\"]\n",
        "            self.learning_rate = config[\"learning_rate\"]\n",
        "            self.hidden1_size = config[\"hidden1_size\"]\n",
        "            self.hidden2_size = config[\"hidden2_size\"]\n",
        "            self.hidden3_size = config[\"hidden3_size\"]\n",
        "            self.is_tuning = True\n",
        "\n",
        "        else:\n",
        "            self.nb_epoch = nb_epoch\n",
        "            self.batch_size = 32\n",
        "            self.learning_rate = 0.0352048104552604\n",
        "            self.hidden1_size = 20\n",
        "            self.hidden2_size = 100\n",
        "            self.hidden3_size = 180\n",
        "            self.is_tuning = False\n",
        "\n",
        "        self.input_size = 128\n",
        "        self.output_size = 128\n",
        "\n",
        "        self.net = Net(self.input_size, self.hidden1_size, self.hidden2_size, self.hidden3_size, self.output_size)\n",
        "        self.siamese_net = SiameseModel(self.net)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.siamese_net.to(device)\n",
        "        print(device)\n",
        "\n",
        "        return\n",
        "\n",
        "    def one_hot_seq(input):\n",
        "        array = []\n",
        "        base_to_int = {\n",
        "            'A': 0,\n",
        "            'T': 1,\n",
        "            'C': 2,\n",
        "            'G': 3\n",
        "        }\n",
        "        for i in input:\n",
        "            array.append(base_to_int[i])\n",
        "        rows = np.max(array) + 1\n",
        "        one_hot = np.eye(rows)[array]\n",
        "        return one_hot\n",
        "\n",
        "\n",
        "    def multiple_seq_to_tensor(input_list):\n",
        "        output_list = []\n",
        "        for i in range(len(input_list)):\n",
        "            array = one_hot_seq(input_list[i])\n",
        "            output_list.append(array.tolist())\n",
        "        tensor = torch.tensor(output_list)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "    def _preprocessor(self, train_sequence_0, train_sequence_1, training=False):\n",
        "\n",
        "        processed_original = multiple_seq_to_tensor(train_sequence_0)\n",
        "        processed_mutated = multiple_seq_to_tensor(train_sequence_1)\n",
        "\n",
        "        return processed_original, processed_mutated\n",
        "\n",
        "    def test_loop(self, epoch, validation_dataloader, stats=False):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        model = self.siamese_net\n",
        "        model.eval()\n",
        "\n",
        "        original_seq = []\n",
        "        mutated_seq = []\n",
        "        original_hashed = []\n",
        "        mutated_hashed = []\n",
        "        ori_mismatches = []\n",
        "        mismatches = []\n",
        "    \n",
        "        for step, batch in enumerate(tqdm(validation_dataloader, position=0, leave=True)):\n",
        "\n",
        "            b_original_seq, b_mutated_seq = batch\n",
        "            b_original_seq = b_original_seq.to(device)\n",
        "            b_mutated_seq = b_mutated_seq.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                loss, average_mismatches, (in_0, in_1), b_original_mismatches, (pred_0, pred_1), b_mismatches, (logits_0, logits_1) = model.forward(b_original_seq, b_mutated_seq)\n",
        "        \n",
        "            for i in range(len(b_original_seq)):\n",
        "                original_seq.append(in_0[i])\n",
        "                mutated_seq.append(in_1[i])\n",
        "                original_hashed.append(pred_0[i])\n",
        "                mutated_hashed.append(pred_1[i])\n",
        "                ori_mismatches.append(b_original_mismatches[i])\n",
        "                mismatches.append(b_mismatches[i])\n",
        "\n",
        "        if stats:\n",
        "            test_info = {'original_seq': original_seq,\n",
        "                'mutated_seq': mutated_seq,\n",
        "                'original_hashed': original_hashed,\n",
        "                'mutated_hashed': mutated_hashed,\n",
        "                'original_mismatches': ori_mismatches,\n",
        "                'hashed_mismatches': mismatches}\n",
        "            test_info_df = pd.DataFrame.from_dict(test_info)\n",
        "            test_info_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/test_info_df_epoch_{}.csv'.format(config, epoch))\n",
        "\n",
        "        average_mismatches = sum(mismatches)/len(mismatches)\n",
        "        print(\"Test: On average, there are {} mismatches\".format(average_mismatches))\n",
        "        return average_mismatches\n",
        "\n",
        "\n",
        "    def train_loop(self, epoch, train_dataloader, optimizer, train_loss_set, stats=False):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        model = self.siamese_net\n",
        "\n",
        "        original_seq = []\n",
        "        mutated_seq = []\n",
        "        original_hashed = []\n",
        "        mutated_hashed = []\n",
        "        original_mismatches = []\n",
        "        mismatches = []\n",
        "\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
        "\n",
        "            model.to(device)\n",
        "            model.train()\n",
        "\n",
        "            b_original_seq, b_mutated_seq = batch\n",
        "            b_original_seq = b_original_seq.to(device)\n",
        "            b_mutated_seq = b_mutated_seq.to(device)\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss, average_mismatches, (in_0, in_1), ori_b_mismatches, (pred_0, pred_1), b_mismatches, (logits_0, logits_1) = model.forward(b_original_seq, b_mutated_seq)\n",
        "        \n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean()\n",
        "            train_loss_set.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            for i in range(len(b_original_seq)):\n",
        "                original_seq.append(in_0[i])\n",
        "                mutated_seq.append(in_1[i])\n",
        "                original_hashed.append(pred_0[i])\n",
        "                mutated_hashed.append(pred_1[i])\n",
        "                original_mismatches.append(ori_b_mismatches[i])\n",
        "                mismatches.append(b_mismatches[i])\n",
        "\n",
        "        if stats:\n",
        "            train_info = {'original_seq': original_seq,\n",
        "                    'mutated_seq': mutated_seq,\n",
        "                    'original_hashed': original_hashed,\n",
        "                    'mutated_hashed': mutated_hashed,\n",
        "                    'original_mismatches': original_mismatches,\n",
        "                    'mismatches': mismatches}\n",
        "            train_info_df = pd.DataFrame.from_dict(train_info)\n",
        "            train_info_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/train_info_df_epoch_{}.csv'.format(config, epoch))\n",
        "        \n",
        "        average_mismatches = sum(mismatches)/len(mismatches)\n",
        "        average_loss = sum(train_loss_set)/len(train_loss_set)\n",
        "        print(\"Train: On average, there are {} mismatches for epoch {}\".format(average_mismatches, epoch))\n",
        "        print(\"Train: On average, the training loss is {} for epoch {}\".format(average_loss, epoch))\n",
        "        return average_mismatches\n",
        "\n",
        "\n",
        "    def fit(self, train_sequence_0, train_sequence_1):\n",
        "\n",
        "        train_sequence_0, validation_sequence_0, train_sequence_1, validation_sequence_1 = train_test_split(train_sequence_0, train_sequence_1,\n",
        "                                                                                    random_state=42, test_size=0.1)\n",
        "        train_sequence_0, train_sequence_1 = self._preprocessor(train_sequence_0, train_sequence_1, training=True)\n",
        "        validation_sequence_0, validation_sequence_1 = self._preprocessor(validation_sequence_0, validation_sequence_1, training=True)  # Do not forget\n",
        "\n",
        "        train_data = torch.utils.data.TensorDataset(train_sequence_0, train_sequence_1)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size)\n",
        "\n",
        "        validation_data = torch.utils.data.TensorDataset(validation_sequence_0, validation_sequence_1)\n",
        "        validation_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=self.batch_size)\n",
        "\n",
        "        optimizer = optim.SGD(self.net.parameters(), lr=self.learning_rate)\n",
        "        \n",
        "        test_average_mismatches = []\n",
        "\n",
        "        train_loss_set = []\n",
        "        train_average_mismatches = []\n",
        "\n",
        "        last_validation_mismatch = 0\n",
        "\n",
        "        for epoch in range(self.nb_epoch):\n",
        "            print(\"Epoch: {}\".format(epoch))\n",
        "            stats_on = True\n",
        "            train_average_mismatch = self.train_loop(epoch, train_dataloader, optimizer, train_loss_set, stats=stats_on)\n",
        "            train_average_mismatches.append(train_average_mismatch)\n",
        "            test_average_mismatch = self.test_loop(epoch, validation_dataloader, stats=stats_on)\n",
        "            test_average_mismatches.append(test_average_mismatch)\n",
        "            last_validation_mismatch = test_average_mismatch\n",
        "\n",
        "        if self.is_tuning:\n",
        "            tune.report(mismatches=last_validation_mismatch)\n",
        "\n",
        "        train_average_mismatches_df = pd.DataFrame(data=train_average_mismatches)\n",
        "        train_average_mismatches_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/train_average_mismatches.csv'.format(config))\n",
        "\n",
        "        test_average_mismatches_df = pd.DataFrame(data=test_average_mismatches)\n",
        "        test_average_mismatches_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/test_average_mismatches.csv'.format(config))\n",
        "\n",
        "        train_loss_df = pd.DataFrame(data=train_loss_set)\n",
        "        train_loss_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/training_losses.csv'.format(config))\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def loop_helper(self, count, sequence_0, sequence_1, called_by_score=False):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        sequence_0, sequence_1 = self._preprocessor(sequence_0, sequence_1, training=False)\n",
        "        data = torch.utils.data.TensorDataset(sequence_0, sequence_1)\n",
        "        dataloader = torch.utils.data.DataLoader(data, batch_size=self.batch_size)\n",
        "\n",
        "        model = self.siamese_net\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        original_seq = []\n",
        "        mutated_seq = []\n",
        "        original_hashed = []\n",
        "        mutated_hashed = []\n",
        "        original_mismatches = []\n",
        "        mismatches = []\n",
        "        logits_0 = []\n",
        "        logits_1 = []\n",
        "    \n",
        "        for step, batch in enumerate(tqdm(dataloader, position=0, leave=True)):\n",
        "\n",
        "            b_original_seq, b_mutated_seq = batch\n",
        "            b_original_seq = b_original_seq.to(device)\n",
        "            b_mutated_seq = b_mutated_seq.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                loss, average_mismatches, (in_0, in_1), ori_b_mismatches, (pred_0, pred_1), b_mismatches, (logit_0, logit_1) = model.forward(b_original_seq, b_mutated_seq)\n",
        "        \n",
        "            logit_0 = logit_0.tolist()\n",
        "            logit_1 = logit_1.tolist()\n",
        "\n",
        "            for i in range(len(b_original_seq)):\n",
        "                original_seq.append(in_0[i])\n",
        "                mutated_seq.append(in_1[i])\n",
        "                original_hashed.append(pred_0[i])\n",
        "                mutated_hashed.append(pred_1[i])\n",
        "                original_mismatches.append(ori_b_mismatches[i])\n",
        "                mismatches.append(b_mismatches[i])\n",
        "                logits_0.append(logit_0[i])\n",
        "                logits_1.append(logit_1[i])\n",
        "\n",
        "        logits_0 = torch.FloatTensor(logits_0)\n",
        "        logits_1 = torch.FloatTensor(logits_1)\n",
        "\n",
        "        hash_info = {'original_seq': original_seq,\n",
        "                 'mutated_seq': mutated_seq,\n",
        "                 'original_hashed': original_hashed,\n",
        "                 'mutated_hashed': mutated_hashed,\n",
        "                 'original_mismatches': original_mismatches,\n",
        "                 'mismatches': mismatches}\n",
        "        hash_info_df = pd.DataFrame.from_dict(hash_info)\n",
        "        hash_info_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/loop{}_info.csv'.format(config, count))\n",
        "\n",
        "        average_mismatches = sum(mismatches)/len(mismatches)\n",
        "        print(\"Loop: On average, there are {} mismatches\".format(average_mismatches))\n",
        "        return average_mismatches, original_hashed, mutated_hashed, logits_0, logits_1\n",
        "\n",
        "\n",
        "    def loop(self, no_of_loops, sequence_0, sequence_1):\n",
        "\n",
        "        in_0 = sequence_0\n",
        "        in_1 = sequence_1\n",
        "\n",
        "        average_mismatches = []\n",
        "\n",
        "        for loop in range(no_of_loops):\n",
        "\n",
        "            average_mismatch, in_0, in_1, logits_0, logits_1 = self.loop_helper(loop, in_0, in_1)\n",
        "            average_mismatches.append(average_mismatch)\n",
        "\n",
        "        average_mismatches_df = pd.DataFrame(data=average_mismatches)\n",
        "        average_mismatches_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/loop_average_mismatches.csv'.format(config))\n",
        "\n",
        "        return in_0, in_1\n",
        "\n",
        "\n",
        "    def evaluate_loop(self, no_of_loops, sequence_0, sequence_1, temp, primer_length, subconfig):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        in_0, in_1 = sequence_0, sequence_1\n",
        "\n",
        "        average_mismatches = []\n",
        "\n",
        "        for loop in range(no_of_loops):\n",
        "\n",
        "            average_mismatch, in_0, in_1, logits_0, logits_1 = self.loop_helper(loop, in_0, in_1)\n",
        "            average_mismatches.append(average_mismatch)\n",
        "      \n",
        "        out_0 = logits_to_primer(logits_0, temp, primer_length)\n",
        "        out_1 = logits_to_primer(logits_1, temp, primer_length)\n",
        "        \n",
        "        original_mismatches = []\n",
        "        hashed_mismatches = []\n",
        "        actual_temp_0 = []\n",
        "        actual_temp_1 = []\n",
        "\n",
        "        size = len(sequence_0)\n",
        "        for x in range(size):\n",
        "            original_mismatch = sum(1 for a, b in zip(sequence_0[x], sequence_1[x]) if a != b)\n",
        "            original_mismatches.append(original_mismatch)\n",
        "\n",
        "            temp_0 = seq_to_temp(out_0[x])\n",
        "            actual_temp_0.append(temp_0)\n",
        "\n",
        "            temp_1 = seq_to_temp(out_1[x])\n",
        "            actual_temp_1.append(temp_1)            \n",
        "\n",
        "            hashed_mismatch = sum(1 for a, b in zip(out_0[x], out_1[x]) if a != b)\n",
        "            hashed_mismatches.append(hashed_mismatch)\n",
        "        \n",
        "        loop_info = {'original_seq': sequence_0,\n",
        "                 'mutated_seq': sequence_1,\n",
        "                 'original_hashed': out_0,\n",
        "                 'mutated_hashed': out_1,\n",
        "                 'temp_original_hashed': actual_temp_0,\n",
        "                 'temp_mutated_hashed': actual_temp_1,\n",
        "                 'original_mismatches': original_mismatches,\n",
        "                 'hashed_mismatches': hashed_mismatches}\n",
        "        loop_info_df = pd.DataFrame(loop_info)\n",
        "        loop_info_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/{}_overall_loop_info.csv'.format(config, subconfig))\n",
        "\n",
        "        average_mismatches_df = pd.DataFrame(data=average_mismatches)\n",
        "        average_mismatches_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/{}_loop_average_mismatches.csv'.format(config, subconfig))\n",
        "\n",
        "        average_mismatches = sum(original_mismatches)/len(original_mismatches)\n",
        "        print(\"Predict: On average, there are {} mismatches\".format(average_mismatches))\n",
        "\n",
        "        average_temp_0 = sum(actual_temp_0)/len(actual_temp_0)\n",
        "        average_temp_1 = sum(actual_temp_1)/len(actual_temp_1)\n",
        "        print(\"Predict: On average, the melting temperatures are {} and {}\".format(average_temp_0, average_temp_1))\n",
        "\n",
        "\n",
        "    def loop_helper_no_stats(self, count, sequence_0, sequence_1, called_by_score=False):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        sequence_0, sequence_1 = self._preprocessor(sequence_0, sequence_1, training=False)\n",
        "        data = torch.utils.data.TensorDataset(sequence_0, sequence_1)\n",
        "        dataloader = torch.utils.data.DataLoader(data, batch_size=self.batch_size)\n",
        "\n",
        "        model = self.siamese_net\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        logits_0 = []\n",
        "        logits_1 = []\n",
        "        original_hashed = []\n",
        "        mutated_hashed = []\n",
        "    \n",
        "        for step, batch in enumerate(tqdm(dataloader, position=0, leave=True)):\n",
        "\n",
        "            b_original_seq, b_mutated_seq = batch\n",
        "            b_original_seq = b_original_seq.to(device)\n",
        "            b_mutated_seq = b_mutated_seq.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                loss, average_mismatches, (in_0, in_1), ori_b_mismatches, (pred_0, pred_1), b_mismatches, (logit_0, logit_1) = model.forward(b_original_seq, b_mutated_seq)\n",
        "        \n",
        "            logit_0 = logit_0.tolist()\n",
        "            logit_1 = logit_1.tolist()\n",
        "\n",
        "            for i in range(len(b_original_seq)):\n",
        "                logits_0.append(logit_0[i])\n",
        "                logits_1.append(logit_1[i])\n",
        "                original_hashed.append(pred_0[i])\n",
        "                mutated_hashed.append(pred_1[i])\n",
        "\n",
        "        logits_0 = torch.FloatTensor(logits_0)\n",
        "        logits_1 = torch.FloatTensor(logits_1)\n",
        "\n",
        "        return original_hashed, mutated_hashed, logits_0, logits_1\n",
        "\n",
        "\n",
        "    def hash(self, file, no_of_loops, temp, primer_length):\n",
        "        \n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        df = pd.read_csv(file)\n",
        "        sequences = list(df['original_seq'])\n",
        "\n",
        "        for i in range(len(sequences)):\n",
        "            sequences[i] = makelen128(sequences[i])\n",
        "\n",
        "        sequence = sequences\n",
        "        temps = []\n",
        "\n",
        "        for loop in range(no_of_loops):\n",
        "\n",
        "            sequence, sequence, logits, logits = self.loop_helper_no_stats(loop, sequence, sequence)\n",
        "      \n",
        "        seq_out = logits_to_primer(logits, temp, primer_length)\n",
        "\n",
        "        for x in range(len(seq_out)):\n",
        "\n",
        "            temp = seq_to_temp(seq_out[x])\n",
        "            temps.append(temp)\n",
        "        \n",
        "        hash_info = {'original_seq': sequences,\n",
        "                 'hashed_seq': seq_out,\n",
        "                 'temp_hashed': temps}\n",
        "        hash_info_df = pd.DataFrame(hash_info)\n",
        "        hash_info_df.to_csv('/content/gdrive/My Drive/divergence_hashing_2/{}/hashed.csv'.format(config))\n",
        "\n",
        "\n",
        "    def hash_one_seq(self, seq, no_of_loops, temp, primer_length):\n",
        "        \n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        seq = makelen128(seq)\n",
        "        sequence = [seq]\n",
        "\n",
        "        for loop in range(no_of_loops):\n",
        "\n",
        "            sequence, sequence, logits, logits = self.loop_helper_no_stats(loop, sequence, sequence)\n",
        "      \n",
        "        seq_out = logits_to_primer(logits, temp, primer_length)\n",
        "\n",
        "        temp = seq_to_temp(seq_out[0])\n",
        "\n",
        "        print(\"The hashed sequence of melting temp {} is {}\".format(temp, seq_out))\n",
        "\n",
        "        return seq_out, temp\n",
        "\n",
        "def save_regressor(trained_model):\n",
        "    \"\"\"\n",
        "    Utility function to save the trained regressor model in part2_model.pickle.\n",
        "    \"\"\"\n",
        "    # If you alter this, make sure it works in tandem with load_regressor\n",
        "    with open(root_dir + config + 'model.pickle', 'wb') as target:\n",
        "        pickle.dump(trained_model, target)\n",
        "    print(\"\\nSaved model in model.pickle\\n\")\n",
        "\n",
        "\n",
        "def load_regressor(config):\n",
        "    with open(root_dir + config + 'model.pickle', 'rb') as target:\n",
        "        trained_model = pickle.load(target)\n",
        "    print(\"\\nLoaded model in model.pickle\\n\")\n",
        "    return trained_model\n",
        "\n",
        "def RayTuneHelper(x, y, config):\n",
        "    model = Regressor(config=config)\n",
        "    model.fit(x, y)\n",
        "\n",
        "def RegressorHyperParameterSearch(x, y):\n",
        "\n",
        "    tune_config = {\n",
        "        \"num_epochs\": tune.grid_search([10, 100]),\n",
        "        \"batch_size\": tune.grid_search([6, 32]),\n",
        "        \"learning_rate\": tune.loguniform(1e-6, 1e-1),\n",
        "        \"hidden1_size\": tune.grid_search([20, 100, 180]),\n",
        "        \"hidden2_size\": tune.grid_search([20, 100, 180]),\n",
        "        \"hidden3_size\": tune.grid_search([20, 100, 180])\n",
        "    }\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=[\"num_epochs\", \"batch_size\", \"learning_rate\", \"hidden1_size\", \"hidden2_size\", \"hidden3_size\"],\n",
        "        metric_columns=[\"mismatches\"],\n",
        "        print_intermediate_tables=True\n",
        "    )\n",
        "\n",
        "    result = tune.run(\n",
        "        partial(RayTuneHelper, x, y),\n",
        "        config=tune_config,\n",
        "        progress_reporter=reporter\n",
        "    )\n",
        "\n",
        "    best_trial = result.get_best_trial(metric=\"mismatches\", mode=\"max\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "\n",
        "    return best_trial.config"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHJOoQz7dX6F",
        "outputId": "43697461-21fa-45a7-a0f6-5c88ad1e5dfc"
      },
      "source": [
        "def example_main():\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    root_dir = ''\n",
        "    os.makedirs(config, exist_ok=True)\n",
        "    df = pd.read_csv(\"2500.csv\")\n",
        "    #df = pd.read_csv(\"100thousand_upto1.csv\")\n",
        "    sequence_pairs = [list(df['seq1']),list(df['seq2'])]\n",
        "\n",
        "    train_sequence_0, test_sequence_0, train_sequence_1, test_sequence_1 = train_test_split(sequence_pairs[0], sequence_pairs[1], test_size=0.10, shuffle=True, random_state=1)\n",
        "\n",
        "    # Uncomment for hyperparameter search\n",
        "    #RegressorHyperParameterSearch(train_sequence_0, train_sequence_1)\n",
        "\n",
        "    regressor = Regressor(nb_epoch=10)\n",
        "    regressor.fit(train_sequence_0, train_sequence_1)\n",
        "    regressor.evaluate_loop(10, test_sequence_0, test_sequence_1, 60, 20, \"test\")\n",
        "\n",
        "    save_regressor(regressor)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    example_main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|██████████| 64/64 [00:01<00:00, 33.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.310123456790123 mismatches for epoch 0\n",
            "Train: On average, the training loss is -0.004008214866189519 for epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 68.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.724444444444444 mismatches\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 37.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.318024691358024 mismatches for epoch 1\n",
            "Train: On average, the training loss is -0.0040355802957492415 for epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 72.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.653333333333334 mismatches\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 38.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.26962962962963 mismatches for epoch 2\n",
            "Train: On average, the training loss is -0.004063394421488435 for epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 69.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.484444444444444 mismatches\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 38.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.25925925925926 mismatches for epoch 3\n",
            "Train: On average, the training loss is -0.004091623126441846 for epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 80.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.528888888888888 mismatches\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 38.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.22469135802469 mismatches for epoch 4\n",
            "Train: On average, the training loss is -0.004120249212428461 for epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 69.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.475555555555555 mismatches\n",
            "Epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.234567901234568 mismatches for epoch 5\n",
            "Train: On average, the training loss is -0.004149334709533529 for epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 79.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.471111111111112 mismatches\n",
            "Epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 39.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.211851851851852 mismatches for epoch 6\n",
            "Train: On average, the training loss is -0.004178760359146898 for epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 58.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.528888888888888 mismatches\n",
            "Epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 38.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.16246913580247 mismatches for epoch 7\n",
            "Train: On average, the training loss is -0.0042084836254616675 for epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 55.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.511111111111111 mismatches\n",
            "Epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 41.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.187160493827161 mismatches for epoch 8\n",
            "Train: On average, the training loss is -0.004238493043279353 for epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 73.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.497777777777777 mismatches\n",
            "Epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 38.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: On average, there are 12.166913580246913 mismatches for epoch 9\n",
            "Train: On average, the training loss is -0.004268812769805663 for epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 70.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: On average, there are 11.524444444444445 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 60.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 12.1 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 59.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 40.996 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 51.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 69.368 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 58.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 84.448 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 55.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 91.476 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 49.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 93.58 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 63.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 95.296 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 56.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 95.388 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 60.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 95.428 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 60.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 95.592 mismatches\n",
            "Predict: On average, there are 1.0 mismatches\n",
            "Predict: On average, the melting temperatures are 59.70000000000025 and 59.70000000000025\n",
            "\n",
            "Saved model in model.pickle\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnIuXHBF2Nnd",
        "outputId": "a1f95d8d-a737-4885-c47f-d6aa008fea10"
      },
      "source": [
        "# the following shows how to use the hashing function after having trained a model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "root_dir = ''\n",
        "config = \"mismatch_analysis\"\n",
        "os.makedirs(config, exist_ok=True)\n",
        "\n",
        "regressor = load_regressor(\"tuned\")\n",
        "'''\n",
        "one_df = pd.read_csv(\"one.csv\")\n",
        "\n",
        "one_0, one_1 = list(one_df['seq1']),list(one_df['seq2'])\n",
        "regressor.evaluate_loop(10, one_0, one_1, 62, 20, \"one\")\n",
        "\n",
        "two_df = pd.read_csv(\"two.csv\")\n",
        "two_0, two_1 = list(two_df['seq1']),list(two_df['seq2'])    \n",
        "regressor.evaluate_loop(10, two_0, two_1, 62, 20, \"two\")\n",
        "\n",
        "three_df = pd.read_csv(\"three.csv\")\n",
        "three_0, three_1 = list(three_df['seq1']),list(three_df['seq2'])\n",
        "regressor.evaluate_loop(10, three_0, three_1, 62, 20, \"three\")\n",
        "'''\n",
        "test = \"AGTATTTATCAGCCCTCGCTGGATATAAGCCTGAAATCCAGGATCGCATGAAGTCCCCCCCGATACCTGGAGTGGATCCCTATGTTCGCGCAACGAACACGCGGATTTTACAGGGTGAATCACAGATT\"\n",
        "regressor.hash_one_seq(test, 10, 60, 20)\n",
        "\n",
        "test2 = \"AGTATTTATCAGCCCTCGCTGGATATAAGCCTGAAATCCAGGATCGCATGAAGTCCCCCCCGATACCTGGAGTGGCTCCCTATGTTCGCGCAACGAACACGCGGATTTTACAGGGTGAATCACAGATT\"\n",
        "regressor.hash_one_seq(test2, 10, 60, 20)\n",
        "\n",
        "regressor.hash(\"loop0_info.csv\", 10, 60, 20)\n",
        "\n",
        "df = pd.read_csv(\"2500.csv\")\n",
        "#df = pd.read_csv(\"100thousand_upto1.csv\")\n",
        "sequence_pairs = [list(df['seq1']),list(df['seq2'])]\n",
        "\n",
        "train_sequence_0, test_sequence_0, train_sequence_1, test_sequence_1 = train_test_split(sequence_pairs[0], sequence_pairs[1], test_size=0.10, shuffle=True, random_state=1)\n",
        "\n",
        "regressor.evaluate_loop(10, test_sequence_0, test_sequence_1, 60, 20, \"test\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded model in model.pickle\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.53it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 164.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 160.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 327.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 157.43it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 401.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 158.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 177.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 151.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 140.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hashed sequence of melting temp 59.7 is ['CACCTCCCTTCTCCAGGATC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 171.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 125.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 154.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 146.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 149.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 193.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 142.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 157.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 159.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hashed sequence of melting temp 59.7 is ['TGCTGTGTGGTGGTCGTGGA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 65.39it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 62.26it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 64.17it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 53.08it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.21it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 63.17it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 60.33it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 63.14it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 54.63it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 62.79it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 62.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 12.264 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 55.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 39.772 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 56.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 66.732 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 48.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 82.272 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 57.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 90.16 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 52.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 92.556 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 50.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 95.016 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 51.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 96.472 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 52.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 96.192 mismatches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 50.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: On average, there are 96.452 mismatches\n",
            "Predict: On average, there are 1.0 mismatches\n",
            "Predict: On average, the melting temperatures are 59.70000000000025 and 59.70000000000025\n"
          ]
        }
      ]
    }
  ]
}